knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library("tidyverse")
library("janitor")
library("lubridate") #this will help us manage dates
files <- list.files(path = "data/spiders", pattern = ".csv", full.names = TRUE)
files
spider_list <- lapply(files, read_csv)
spider_list[[3]]
spider_list[[2]]
names(spider_list[[1]])
names <- list.files(path = "data/spiders", pattern = ".csv")
names
names_list <- strsplit(names, split = " .csv")
names_list
names_vec <- unlist(names_list)
names_vec
names(spider_list) <- names_vec
names(spider_list)
butte <- spider_list[["Butte"]]
spider_list[["Butte"]]
spiders_all <- bind_rows(spider_list)
spiders_all
table_A <- read_csv("data/table_A.csv")
table_B <- read_csv("data/table_B.csv")
table_A
table_B
join_type(firstTable, secondTable, by=columnTojoinOn)
inner_exampleDF <- inner_join(table_A, table_B, by="customer_ID")
inner_exampleDF
left_exampleDF <- left_join(table_A, table_B, by="customer_ID")
left_exampleDF
right_exampleDF <- right_join(table_A, table_B, by="customer_ID")
right_exampleDF
full_exampleDF <- full_join(table_A, table_B, by="customer_ID")
full_exampleDF
anti_exampleDF <- anti_join(table_A, table_B, by="customer_ID")
anti_exampleDF
spiders_locs <- read_csv("data/spiders locations/spiders_locations.csv")
spiders_w_locs <- spiders_locs %>%
left_join(spiders_all, spiders_locs, by ="Accession")
summary(spiders_w_locs)
class(spiders_with_locs$Date)
spiders_with_locs <- spiders_locs %>%
left_join(spiders_all, spiders_locs, by ="Accession")
summary(spiders_with_locs)
class(spiders_with_locs$Date)
#glimpse(spiders_with_locs)
day <- today()
day
str(day)
datetime <- now()
datetime
dmy(spiders_with_locs$Date)
dateformat1 <- "20200922"
dateformat2 <- "09-22-2020"
dateformat3 <- "22/09/2020"
dateformat4 <- "09-22-2020 17:00:00"
dateformat5 <- "20200922 170000"
mdy(dateformat2)
dmy(dateformat3)
mdy_hms(dateformat4)
ymd_hms(dateformat5)
ymd(dateformat1)
write.csv(spiders_with_locs, file = "spiders_with_locs.csv", row.names = FALSE)
register_stadiamaps("e77f55a8-a371-44cd-a7dd-6384b4586d64", write = FALSE)
install.packages("ggmap")
library(ggmap)
register_stadiamaps("e77f55a8-a371-44cd-a7dd-6384b4586d64", write = FALSE)
spiders <- read_csv("data/spiders_with_locs.csv")%>% clean_names()
spiders <- spiders %>% filter(latitude<=42)
spiders %>%
select(latitude, longitude) %>%
summary()
lat <- c(34.67, 41.80)
long <- c(-124.1, -115.5)
bbox <- make_bbox(long, lat, f = 0.03) #f is the fraction of the bounding box to add to the range
map1 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7)
ggmap(map1)
ggmap(map1) +
geom_point(data = spiders, aes(longitude, latitude), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Spider Locations")
sharks <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>%
clean_names() %>%
filter(longitude !="NA" & latitude !="NA") %>% # pulling out NA locations
mutate(longitude = as.numeric(longitude)) # converting longitude to numeric
sharks_dups <- sharks %>%
distinct(location, .keep_all = TRUE) # remove duplicate locations, but keep the remaining variables
sharks_dups <- sharks %>%
distinct(location, .keep_all = TRUE) # remove duplicate locations, but keep the remaining variables
